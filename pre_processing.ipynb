{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import click\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import data1\n",
    "from data1 import STD, MEAN, BALANCE_WEIGHTS, U, EV, no_augmentation_params\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing arrays for different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_class_0 = []\n",
    "image_class_1 = []\n",
    "image_class_2 = []\n",
    "image_class_3 = []\n",
    "image_class_4 = []\n",
    "image_labels_0 = 0 \n",
    "image_labels_1 = 0\n",
    "image_labels_2 = 0\n",
    "image_labels_3 = 0\n",
    "image_labels_4 = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read csv file to get all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_labels = pd.read_csv(\"temp.csv\",index_col=0)\n",
    "col_name = \"level\"\n",
    "image_labels_0 = len(true_labels[true_labels['level']==0].index)\n",
    "image_labels_1 = len(true_labels[true_labels['level']==1].index)\n",
    "image_labels_2 = len(true_labels[true_labels['level']==2].index)\n",
    "image_labels_3 = len(true_labels[true_labels['level']==3].index)\n",
    "image_labels_4 = len(true_labels[true_labels['level']==4].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label0 = [0 for i in range(image_labels_0)]\n",
    "label1 = [1 for i in range(image_labels_1)]\n",
    "label2 = [2 for i in range(image_labels_2)]\n",
    "label3 = [3 for i in range(image_labels_3)]\n",
    "label4 = [4 for i in range(image_labels_4)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method required to getting the coordinates of bounding box\n",
    "Code - https://github.com/sveitser/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square_bbox(img):\n",
    "    w, h = img.size\n",
    "    left = max((w-h)//2, 0)\n",
    "    upper = 0\n",
    "    right = min(w - (w-h) // 2, w)\n",
    "    lower = h\n",
    "    return (left, upper, right, lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur the image and convert it to required size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(fname, crop_size):\n",
    "    img = Image.open(fname)\n",
    "    \n",
    "    blurred = img.filter(ImageFilter.BLUR)\n",
    "    after_blur = np.array(blurred)\n",
    "    h, w, _ = after_blur.shape\n",
    "    \n",
    "    # why check this?\n",
    "    # got after analyzing the input\n",
    "    \n",
    "    if w > 1.2*h:\n",
    "        lmax = after_blur[:, : w//32, :].max(axis=(0,1)).astype(int)\n",
    "        rmax = after_blur[:, -w//32:, :].max(axis=(0,1)).astype(int)\n",
    "        max_background = np.maximum(lmax, rmax)\n",
    "        foreground = (after_blur > max_background + 10).astype(np.uint8)\n",
    "        bbox = Image.fromarray(foreground).getbbox()\n",
    "        \n",
    "        if bbox is None:\n",
    "            print('bbox none for {} (???)'.format(fname))\n",
    "        else:\n",
    "            left, upper, right, lower = bbox\n",
    "            if right - left < 0.8 * h or lower - upper < 0.8 * h:\n",
    "                print(\"box too small\")\n",
    "                bbox = None\n",
    "    else:\n",
    "        bbox = None\n",
    "    if bbox is None:\n",
    "        bbox = square_bbox(img)\n",
    "    cropped = img.crop(bbox)\n",
    "    resized = cropped.resize([crop_size, crop_size])\n",
    "    return resized\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def save(img, fname):\n",
    "#    img.save(fname, quality=97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def get_convert_fname(fname, directory, convert_directory):\n",
    "#    return fname.replace(directory, convert_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending the image arrays to the corresponding image classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(directory, crop_size):\n",
    "    global image_array_0,image_array_1,image_array_2,image_array_3,image_array_4 \n",
    "    #try:\n",
    "    #    os.mkdir(convert_directory)\n",
    "    #except OSError:\n",
    "    #    pass\n",
    "    # get the filenames - \n",
    "    filenames = [f for dp, dn, fn in os.walk(directory) \n",
    "                for f in fn if f.endswith('jpeg') or f.endswith('tiff')]\n",
    "    # sort it\n",
    "    filenames = sorted(filenames)\n",
    "    #converted_name_to_save = \"\"\n",
    "    \n",
    "    for x in filenames:\n",
    "        #converted_name_to_save = get_convert_fname(x, directory, convert_directory)\n",
    "        img = convert(directory+x, crop_size)\n",
    "        #print(type(img))\n",
    "        #save(img, converted_name_to_save)\n",
    "        if true_labels.loc[x[:-5],col_name] == 0:\n",
    "            image_class_0.append(np.array(img))\n",
    "        elif true_labels.loc[x[:-5],col_name] == 1:\n",
    "            image_class_1.append(np.array(img))\n",
    "        elif true_labels.loc[x[:-5],col_name] == 2:\n",
    "            image_class_2.append(np.array(img))\n",
    "        elif true_labels.loc[x[:-5],col_name] == 3:\n",
    "            image_class_3.append(np.array(img))\n",
    "        else:\n",
    "            image_class_4.append(np.array(img))\n",
    "        #image_array.append(np.array(img))\n",
    "        #image_labels.append(true_labels.loc[x[23:-5],col_name])\n",
    "        #print(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the main method and provide the required crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"try/\", 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(image_labels)\n",
    "#labels = [to_categorical(y) for y in image_labels]\n",
    "#labels\n",
    "#np.array(image_class_0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation done as means to avoid overfitting\n",
    "### Reason - Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ImageDataGenerator(featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.,\n",
    "    zoom_range=[0.9,1.1],\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0 = to_categorical(label0, num_classes=5)\n",
    "label1 = to_categorical(label1, num_classes=5)\n",
    "label2 = to_categorical(label2, num_classes=5)\n",
    "label3 = to_categorical(label3, num_classes=5)\n",
    "label4 = to_categorical(label4, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing rounds argument and batch_size for data augmentation using keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "round0 = 1\n",
    "round1 = 4\n",
    "round2 = 2\n",
    "round3 = 6\n",
    "round4 = 8\n",
    "total_loop_count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "no_batches = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final numpy arrays consisting of images after data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_X = np.empty(shape=(0, 512, 512, 3))\n",
    "final_Y = np.empty(shape=(0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augment(no_batches, X_train_aug):\n",
    "    global final_X, final_Y\n",
    "    x_temp = 0\n",
    "    y_temp = 0\n",
    "    for i in range(no_batches):\n",
    "        x_temp = np.array(X_train_aug.next()[0])\n",
    "        y_temp = np.array(X_train_aug.next()[1])\n",
    "        #print(x_temp.shape)\n",
    "        final_X = np.concatenate((final_X, x_temp), axis=0)\n",
    "        final_Y = np.concatenate((final_Y, y_temp), axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loop_count in range(total_loop_count):\n",
    "    if loop_count==0:\n",
    "        x.fit(np.array(image_class_0), rounds=round0)\n",
    "        if image_labels_0 % batch_size==0:\n",
    "            no_batches = image_labels_0 // batch_size\n",
    "        else:\n",
    "            no_batches = image_labels_0 // batch_size + 1\n",
    "        X_train_aug = x.flow(np.array(image_class_0), label0, seed=0, batch_size=batch_size)\n",
    "        #augment(no_batches, X_train_aug)\n",
    "        for i in range(no_batches):\n",
    "            x_temp = np.array(X_train_aug.next()[0])\n",
    "            y_temp = np.array(X_train_aug.next()[1])\n",
    "            #print(x_temp.shape)\n",
    "            final_X = np.concatenate((final_X, x_temp), axis=0)\n",
    "            final_Y = np.concatenate((final_Y, y_temp), axis=0)\n",
    "\n",
    "            \n",
    "    elif loop_count==1:\n",
    "        x.fit(np.array(image_class_1), rounds=round1)\n",
    "        if image_labels_1 % batch_size==0:\n",
    "            no_batches = image_labels_1 // batch_size\n",
    "        else:\n",
    "            no_batches = image_labels_1 // batch_size + 1\n",
    "        X_train_aug = x.flow(np.array(image_class_1), label1, seed=0, batch_size=batch_size)\n",
    "        augment(no_batches, X_train_aug)\n",
    "\n",
    "    elif loop_count==2:\n",
    "        x.fit(np.array(image_class_2), rounds=round2)\n",
    "        if image_labels_2 % batch_size==0:\n",
    "            no_batches = image_labels_2 // batch_size\n",
    "        else:\n",
    "            no_batches = image_labels_2 // batch_size + 1\n",
    "        X_train_aug = x.flow(np.array(image_class_2), label2, seed=0, batch_size=batch_size)\n",
    "        augment(no_batches, X_train_aug)\n",
    "\n",
    "    elif loop_count==3:\n",
    "        x.fit(np.array(image_class_3), rounds=round3)\n",
    "        if image_labels_3 % batch_size==0:\n",
    "            no_batches = image_labels_3 // batch_size\n",
    "        else:\n",
    "            no_batches = image_labels_3 // batch_size + 1\n",
    "        X_train_aug = x.flow(np.array(image_class_3), label3, seed=0, batch_size=batch_size)\n",
    "        augment(no_batches, X_train_aug)\n",
    "\n",
    "    elif loop_count==4:\n",
    "        x.fit(np.array(image_class_4), rounds=round4)\n",
    "        if image_labels_4 % batch_size==0:\n",
    "            no_batches = image_labels_4 // batch_size\n",
    "        else:\n",
    "            no_batches = image_labels_4 // batch_size + 1\n",
    "        X_train_aug = x.flow(np.array(image_class_4), label4, seed=0, batch_size=batch_size)\n",
    "        augment(no_batches, X_train_aug)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"X_DR1.npy\", final_X)\n",
    "np.save(\"Y_DR1.npy\", final_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
