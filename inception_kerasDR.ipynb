{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input, Flatten, MaxPool2D, Conv2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Inception v3 model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_data_dir = \"try/train\"\\n#validation_data_dir = \"data/val\"\\n#nb_train_samples = 4125\\n#nb_validation_samples = 466 \\nbatch_size = 7\\nepochs = 1\\nfilters = 32'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_width, img_height = 512, 512\n",
    "'''\n",
    "train_data_dir = \"try/train\"\n",
    "#validation_data_dir = \"data/val\"\n",
    "#nb_train_samples = 4125\n",
    "#nb_validation_samples = 466 \n",
    "batch_size = 7\n",
    "epochs = 1\n",
    "filters = 32'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input( shape = (img_width, img_height, 3) )\n",
    "model1 = InceptionV3(input_tensor=inp, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "\n",
    "# convert classes to vector\n",
    "classes = 5\n",
    "y = to_categorical(y, classes).astype(np.float32)\n",
    "\n",
    "# shuffle all the data\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our_inp = Input(shape=model1.output_shape[1:]) \n",
    "conv1 = Conv2D(32, (3,3), strides=(1,1), activation=\"relu\", padding=\"same\")(model1.output)\n",
    "conv2 = Conv2D(64, (5,5), strides=(1,1), activation=\"relu\", padding=\"same\")(conv1)\n",
    "conv3 = Conv2D(128, (7,7), strides=(1,1), activation=\"relu\", padding=\"same\")(conv2)\n",
    "conv4 = Conv2D(256, (9,9), strides=(1,1), activation=\"relu\", padding=\"same\")(conv3)\n",
    "max_layer1 = MaxPool2D(pool_size=(2,2))(conv4)\n",
    "flattened = Flatten()(max_layer1)\n",
    "dense1 = Dense(4096, activation=\"relu\")(flattened)\n",
    "dense2 = Dense(1024, activation=\"relu\")(dense1)\n",
    "dense3 = Dense(512, activation = \"relu\")(dense2)\n",
    "out = Dense(5, activation=\"softmax\")(dense3)\n",
    "\n",
    "#our_model = Model(inputs=our_inp, outputs=out)\n",
    "\n",
    "\n",
    "#print(conv1); print(conv2); print(conv4); print(max_layer1); print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updated_model = Model(inputs=inp, outputs = out)\n",
    "for layer in updated_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "updated_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_model.fit(x=X, y=y, batch_size=7, epochs=200, validation_split=0.01, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\"\",\n",
    "target_size = (512, 512),\n",
    "batch_size = 7, \n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
